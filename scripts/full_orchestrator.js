#!/usr/bin/env node
/**
 * scripts/full_orchestrator.js
 *
 * Full Integrity Orchestrator:
 * - Runs up to 10 rounds of: lint/typecheck -> import/usage analysis -> quarantine unused -> generate playwright tests -> run tests -> DB schema pull + generate migrations (read-only)
 * - Auto-fixes where safe (prettier, eslint --fix)
 * - Moves any candidate unused files to .isolated_trash/<timestamp>/ (no permanent delete)
 * - Produces human-friendly final_delivery_report.json
 *
 * Safety-first: non-destructive by default. Manual final delete only after review.
 */

import fs from "fs";
import path from "path";
import { execSync, spawnSync } from "child_process";
import os from "os";

const ROOT = process.cwd();
const MAX_ROUNDS = 10;
const MIN_ROUNDS_BEFORE_STOP = 3;
const TRASH_ROOT = path.join(ROOT, ".isolated_trash");
const QUARANTINE_DIR = path.join(ROOT, "src/.shared_quarantine");
const USAGE_MAP = path.join(QUARANTINE_DIR, "usage-map.json");
const REPORT_FILE = path.join(ROOT, "final_delivery_report.json");
const PLAYWRIGHT_TESTS_DIR = path.join(ROOT, "tests/auto_generated");
const MIGRATIONS_NEW = path.join(ROOT, "migrations/new");
const MIGRATIONS_BACKUP = path.join(QUARANTINE_DIR, "migrations_backup");
const LOCK_FILE = path.join(QUARANTINE_DIR, ".lock");

const SUPABASE_URL = process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL || "";
const SUPABASE_SERVICE_ROLE = process.env.SUPABASE_SERVICE_ROLE || "";
const SUPABASE_ANON_KEY = process.env.SUPABASE_ANON_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY || "";

function log(...args) { console.log("[Orch]", ...args); }
function ensureDir(dir) { if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true }); }
function timestamp() { return new Date().toISOString().replace(/[:.]/g, "-"); }
function safeExec(cmd, opts = {}) {
  try {
    return execSync(cmd, { stdio: "pipe", encoding: "utf8", ...opts }).trim();
  } catch (e) {
    return { error: e.message, stdout: e.stdout ? e.stdout.toString() : "", stderr: e.stderr ? e.stderr.toString() : "" };
  }
}

// ---------- Utilities ----------
ensureDir(TRASH_ROOT);
ensureDir(QUARANTINE_DIR);
ensureDir(PLAYWRIGHT_TESTS_DIR);
ensureDir(MIGRATIONS_NEW);
ensureDir(MIGRATIONS_BACKUP);

function readUsageMap() {
  if (!fs.existsSync(USAGE_MAP)) return { generatedAt: new Date().toISOString(), files: {} };
  try {
    return JSON.parse(fs.readFileSync(USAGE_MAP, "utf8"));
  } catch { return { generatedAt: new Date().toISOString(), files: {} }; }
}
function writeUsageMap(obj) {
  fs.writeFileSync(USAGE_MAP, JSON.stringify(obj, null, 2), "utf8");
}

function listAllFiles(base = ROOT) {
  const out = [];
  function walk(dir) {
    const entries = fs.readdirSync(dir, { withFileTypes: true });
    for (const e of entries) {
      const p = path.join(dir, e.name);
      if (p.includes("node_modules") || p.includes(".isolated_trash") || p.includes(".git")) continue;
      if (e.isDirectory()) walk(p); else out.push(p);
    }
  }
  try { walk(base); } catch (e) { /* ignore permission issues */ }
  return out;
}

// ---------- Step: Code Quality (lint/typecheck/format) ----------
function runCodeQuality() {
  log("Running code quality checks: prettier, eslint --fix, tsc --noEmit");
  const results = { prettier: null, eslint: null, tsc: null };
  // Prettier
  if (fs.existsSync(path.join(ROOT, "package.json")) && (JSON.parse(fs.readFileSync(path.join(ROOT, "package.json"))).scripts || {})["format"]) {
    results.prettier = safeExec("npm run format");
  } else {
    results.prettier = safeExec("npx prettier --write .");
  }
  // ESLint fix
  if (fs.existsSync(path.join(ROOT, ".eslintrc")) || (fs.existsSync(path.join(ROOT, "package.json")) && JSON.parse(fs.readFileSync(path.join(ROOT, "package.json"))).eslintConfig)) {
    results.eslint = safeExec("npx eslint --ext .js,.jsx,.ts,.tsx . --fix");
  } else {
    results.eslint = { notice: "no eslint config found" };
  }
  // TypeCheck
  if (fs.existsSync(path.join(ROOT, "tsconfig.json"))) {
    results.tsc = safeExec("npx tsc --noEmit");
  } else results.tsc = { notice: "no tsconfig.json â€” skipping typecheck" };

  return results;
}

// ---------- Step: Build import graph / usage map ----------
function buildImportGraph() {
  log("Building import graph (trying madge, fallback static scan) ...");
  const usage = { generatedAt: new Date().toISOString(), files: {} };
  // Try madge
  try {
    const madgeExists = safeExec("npx madge --version");
    if (!madgeExists.error) {
      // produce dependency graph for src
      const madgeOut = safeExec("npx madge --json src || true");
      try {
        const graph = JSON.parse(madgeOut);
        for (const [file, deps] of Object.entries(graph)) {
          usage.files[file] = { deps };
        }
      } catch { /* fallthrough to fallback */ }
    }
  } catch (e) { /* ignore */ }

  // Fallback: scan imports by regex from files (*.ts,*.tsx,*.js,*.jsx)
  const all = listAllFiles();
  const codeFiles = all.filter(f => /\.(ts|tsx|js|jsx)$/.test(f));
  const importRegex = /(?:import\s.*from\s+|require\(['"`])(.+?)['"`\)]/g;
  for (const f of codeFiles) {
    try {
      const txt = fs.readFileSync(f, "utf8");
      const deps = [];
      let m;
      while ((m = importRegex.exec(txt)) !== null) {
        deps.push(m[1]);
      }
      const rel = path.relative(ROOT, f);
      usage.files[rel] = usage.files[rel] || {};
      usage.files[rel].deps = Array.from(new Set([...(usage.files[rel].deps || []), ...deps]));
    } catch (e) { /* ignore read errors */ }
  }

  writeUsageMap(usage);
  return usage;
}

// ---------- Step: Detect candidates (unused files) ----------
function detectUnusedFiles(usageMap) {
  log("Detecting unused files by comparing filesystem vs usage map...");
  const all = listAllFiles().map(p => path.relative(ROOT, p));
  const referenced = new Set();
  for (const [file, meta] of Object.entries(usageMap.files || {})) {
    referenced.add(file);
    (meta.deps || []).forEach(d => {
      // normalize some imports to relative file names heuristically
      if (d.startsWith(".") || d.startsWith("/")) {
        const resolved = path.normalize(path.join(path.dirname(file), d));
        referenced.add(resolved);
      }
    });
  }
  // protect Next.js App Router special files
  const protectedPatterns = ["page.tsx", "layout.tsx", "route.ts", "loading.tsx", "error.tsx", "middleware.ts"];

  const candidates = [];
  for (const f of all) {
    if (protectedPatterns.some(p => f.endsWith(p))) continue;
    // skip obvious non-project files
    if (f.startsWith("public/") || f.startsWith("assets/") || f.includes(".git") ) continue;
    if (!referenced.has(f)) candidates.push(f);
  }
  return candidates;
}

// ---------- Safe move to isolated trash ----------
function moveToIsolated(relPath) {
  const ts = timestamp();
  const destBase = path.join(TRASH_ROOT, ts);
  ensureDir(destBase);
  const src = path.join(ROOT, relPath);
  const dest = path.join(destBase, relPath);
  ensureDir(path.dirname(dest));
  try {
    fs.renameSync(src, dest);
    return { moved: true, src: relPath, dest: path.relative(ROOT, dest) };
  } catch (e) {
    // fallback: copy and keep original (safer)
    try {
      fs.copyFileSync(src, dest);
      return { moved: false, copied: true, src: relPath, dest: path.relative(ROOT, dest) };
    } catch (err) {
      return { error: err.message, src: relPath };
    }
  }
}

// ---------- Playwright test generation ----------
function generatePlaywrightTests() {
  log("Generating Playwright tests (frontend / backend / auth / i18n) ...");
  ensureDir(PLAYWRIGHT_TESTS_DIR);
  const routes = discoverFrontendRoutes();
  const apiEndpoints = discoverApiEndpoints();

  // frontend.spec.ts
  const frontFile = path.join(PLAYWRIGHT_TESTS_DIR, "frontend.spec.ts");
  const frontCode = `import { test, expect } from "@playwright/test";
test.describe("Frontend smoke", () => {
${routes.map(r => `  test("load ${r}", async ({ page }) => { await page.goto("${r}"); await expect(page).toHaveTitle(/.+/); });`).join("\n")}
});
`;
  fs.writeFileSync(frontFile, frontCode, "utf8");

  // backend.spec.ts
  const backFile = path.join(PLAYWRIGHT_TESTS_DIR, "backend.spec.ts");
  const baseApi = process.env.API_URL || "http://localhost:3000";
  const backCode = `import { test, expect } from "@playwright/test";
test.describe("Backend API", () => {
${apiEndpoints.map(ep => `  test("GET ${ep}", async ({ request }) => { const res = await request.get("${baseApi}${ep}"); expect(res.status()).toBeLessThan(500); });`).join("\n")}
});
`;
  fs.writeFileSync(backFile, backCode, "utf8");

  // auth.spec.ts (simple placeholder)
  const authFile = path.join(PLAYWRIGHT_TESTS_DIR, "auth.spec.ts");
  const authCode = `import { test, expect } from "@playwright/test";
test("login flow placeholder", async ({ page }) => {
  await page.goto("/login");
  await expect(page.locator("input[name=email]")).toBeVisible();
});
`;
  fs.writeFileSync(authFile, authCode, "utf8");

  // i18n test (header buttons)
  const uiFile = path.join(PLAYWRIGHT_TESTS_DIR, "ui.spec.ts");
  const uiCode = `import { test, expect } from "@playwright/test";
test("Header language & theme toggles exist", async ({ page }) => {
  await page.goto("/");
  const langBtn = page.locator("[data-test=lang-toggle]");
  const themeBtn = page.locator("[data-test=theme-toggle]");
  await expect(langBtn).toBeVisible();
  await expect(themeBtn).toBeVisible();
  // quick interaction check
  await langBtn.click(); await themeBtn.click();
});
`;
  fs.writeFileSync(uiFile, uiCode, "utf8");

  return { routesCount: routes.length, apiCount: apiEndpoints.length };
}

// ---------- Simple route discovery (heuristic) ----------
function discoverFrontendRoutes() {
  const pagesDir = path.join(ROOT, "src", "app");
  const routes = new Set(["/"]);
  function walk(dir, baseRoute = "") {
    if (!fs.existsSync(dir)) return;
    for (const ent of fs.readdirSync(dir, { withFileTypes: true })) {
      const p = path.join(dir, ent.name);
      if (ent.isDirectory()) {
        // If folder contains page.tsx treat as route
        if (fs.existsSync(path.join(p, "page.tsx"))) {
          const route = path.relative(pagesDir, p).replace(/\\/g, "/");
          routes.add("/" + (route === "" ? "" : route));
        }
        walk(p, baseRoute + "/" + ent.name);
      }
    }
  }
  walk(pagesDir);
  return Array.from(routes);
}

// ---------- Discover API endpoints (heuristic) ----------
function discoverApiEndpoints() {
  const apiDir = path.join(ROOT, "src", "app", "api");
  const endpoints = new Set();
  function walk(dir, prefix = "/api") {
    if (!fs.existsSync(dir)) return;
    for (const ent of fs.readdirSync(dir, { withFileTypes: true })) {
      const p = path.join(dir, ent.name);
      if (ent.isDirectory()) {
        walk(p, prefix + "/" + ent.name);
      } else {
        if (ent.name === "route.ts" || ent.name === "index.ts") {
          // record endpoint
          endpoints.add(prefix);
        }
      }
    }
  }
  walk(apiDir);
  return Array.from(endpoints);
}

// ---------- DB Schema pull (Supabase CLI) ----------
function pullSupabaseSchema() {
  if (!SUPABASE_URL || !SUPABASE_SERVICE_ROLE) {
    return { skipped: true, reason: "Supabase env vars missing" };
  }
  log("Attempting to pull DB schema using supabase CLI (read-only)...");
  ensureDir(path.join(ROOT, "migration_workdir"));
  try {
    // This command requires supabase CLI installed and authenticated OR using direct URL/keys.
    const cmd = `npx supabase db dump --schema-only --file=migration_workdir/schema.sql --project ${SUPABASE_URL.split("//")[1].split(".")[0]}`;
    const out = safeExec(cmd);
    // if not successful, fallback: pg_dump using connection string (not provided here)
    return { success: true, out };
  } catch (e) {
    return { error: e.message || e };
  }
}

// ---------- i18n extraction (simple) ----------
function extractI18n() {
  log("Extracting hard-coded labels for i18n (simple heuristic) ...");
  const all = listAllFiles();
  const textRegex = /(["'`])([\\s\\S]*?[\\p{L}]{2,}[\\s\\S]*?)\\1/gu; // strings with letters
  const keys = new Set();
  for (const f of all.filter(x => /\.(tsx|ts|jsx|js|html)$/.test(x))) {
    try {
      const txt = fs.readFileSync(f, "utf8");
      let m;
      while ((m = textRegex.exec(txt)) !== null) {
        const s = m[2].trim();
        if (s.length > 1 && s.length < 200 && /[A-Za-z\u0600-\u06FF]/u.test(s)) {
          // heuristic: avoid template strings with ${}
          if (!s.includes("${") && !s.startsWith("http") && !s.match(/^\s*[\{\[]/)) {
            keys.add(s);
          }
        }
      }
    } catch (e) { /* ignore unreadable files */ }
  }
  // write translation keys to file for manual review and to import to DB later
  const out = Array.from(keys);
  ensureDir(path.join(ROOT, "i18n"));
  const extractFile = path.join(ROOT, "i18n/extracted_strings.json");
  fs.writeFileSync(extractFile, JSON.stringify(out, null, 2), "utf8");
  return { extracted: out.length, path: extractFile };
}

// ---------- Round evaluation / stability ----------
function evaluateStability(qcResults, testResults, needsReviewCount) {
  const noLintErrors = !(qcResults.tsc && qcResults.tsc.stderr) && !(qcResults.eslint && qcResults.eslint.error);
  const testsPass = testResults && testResults.failed === 0;
  const stable = noLintErrors && testsPass && needsReviewCount === 0;
  return { stable, details: { noLintErrors, testsPass, needsReviewCount } };
}

// ---------- Run Playwright tests ----------
function runPlaywrightTests() {
  log("Running Playwright tests...");
  try {
    // ensure playwright config exists? many projects don't; just run tests folder
    const out = safeExec(`npx playwright test ${PLAYWRIGHT_TESTS_DIR} --reporter=list`, { maxBuffer: 10 * 1024 * 1024 });
    // minimal parse: check "failed" lines
    const failed = /failed\s+(\d+)/i.exec(out.stdout || out) || [null, 0];
    const failedCount = Number(failed[1] || 0);
    return { success: failedCount === 0, failed: failedCount, raw: out };
  } catch (e) {
    return { error: e.message || e, raw: e.stdout || "" };
  }
}

// ---------- Main orchestrator ----------
async function orchestrate() {
  const summary = {
    rounds: [],
    final: null
  };

  for (let round = 1; round <= MAX_ROUNDS; round++) {
    log("========== ROUND", round, "==========");
    // Acquire simple lock
    if (fs.existsSync(LOCK_FILE)) {
      log("Lock file present, waiting a bit...");
      await new Promise(r => setTimeout(r, 2000));
    }
    fs.writeFileSync(LOCK_FILE, `lock by orchestrator ${process.pid} at ${new Date().toISOString()}`);

    // 1) Code quality (format/lint/tsc)
    const qcResults = runCodeQuality();

    // 2) Build import graph / usage map
    const usageMap = buildImportGraph();

    // 3) Detect unused files
    const candidates = detectUnusedFiles(usageMap);
    log("Candidates detected:", candidates.length);

    // Safety checks: don't move tests, migrations, env, .git files, package files, public assets
    const safeCandidates = candidates.filter(c =>
      !c.includes("migrations") && !c.includes("node_modules") && !c.includes(".git") && !c.startsWith("public/") && !c.startsWith("assets/") && !c.endsWith(".env") && !c.endsWith(".env.local")
    );

    // Move candidates to trash (but mark them as 'needs-review' if small doubt)
    const moved = [];
    for (const c of safeCandidates) {
      // additional heuristics: if file name contains 'mock'|'test'|'spec'|'example' -> immediate move
      const lower = c.toLowerCase();
      if (/mock|test|spec|example|\.bak|\.old|temp|fixture/.test(lower)) {
        const res = moveToIsolated(c);
        moved.push(res);
      } else {
        // if uncertain -> move to quarantine area under needs-review
        const res = moveToIsolated(c);
        moved.push(res);
      }
    }

    // 4) Extract i18n strings
    const i18nRes = extractI18n();

    // 5) Pull DB schema (if supabase available)
    const dbRes = pullSupabaseSchema();

    // 6) Generate Playwright tests
    const genRes = generatePlaywrightTests();

    // 7) Run Playwright tests
    const playRes = runPlaywrightTests();

    // 8) Collate round report
    const roundReport = {
      round,
      timestamp: new Date().toISOString(),
      qcResultsSummary: {
        prettier: !!qcResults.prettier,
        eslint: qcResults.eslint && !qcResults.eslint.error,
        tsc: qcResults.tsc && !qcResults.tsc.stderr
      },
      usageMapSummary: { filesScanned: Object.keys(usageMap.files || {}).length },
      candidatesCount: candidates.length,
      movedCount: moved.length,
      i18n: i18nRes,
      db: dbRes,
      playRes: playRes && (playRes.failed !== undefined ? { failed: playRes.failed } : playRes),
    };

    summary.rounds.push(roundReport);
    // update usage-map file on disk
    writeUsageMap(usageMap);

    // evaluate stability
    const needsReviewCount = moved.length; // simple proxy
    const stableEval = evaluateStability(qcResults, playRes, needsReviewCount);
    log("Stability evaluation:", stableEval);

    // release lock
    try { fs.unlinkSync(LOCK_FILE); } catch (e) { /* ignore */ }

    // stop early if stable and we are past minimum rounds
    if (stableEval.stable && round >= MIN_ROUNDS_BEFORE_STOP) {
      log("System stable and criteria satisfied â€” stopping early at round", round);
      break;
    } else {
      log("Round", round, "completed. Proceeding to next round if any.");
    }
    // small delay between rounds
    await new Promise(r => setTimeout(r, 1500));
  }

  // Post processing: create final report and rollback bundle (tar)
  const finalReport = {
    generatedAt: new Date().toISOString(),
    summary
  };
  fs.writeFileSync(REPORT_FILE, JSON.stringify(finalReport, null, 2), "utf8");
  log("Final report written to", REPORT_FILE);

  // create rollback bundle of current trash
  try {
    const bundleName = `rollback_bundle_${timestamp()}.tar.gz`;
    const bundlePath = path.join(TRASH_ROOT, bundleName);
    ensureDir(TRASH_ROOT);
    // use tar if available
    try {
      safeExec(`tar -czf "${bundlePath}" -C "${TRASH_ROOT}" .`);
      log("Rollback bundle created at", bundlePath);
    } catch (e) {
      log("tar failed or unavailable - skipping rollback bundle creation", e);
    }
  } catch (e) {
    log("Failed creating rollback bundle:", e);
  }

  log("Orchestration complete. Please review", REPORT_FILE, "and inspect", TRASH_ROOT, "before any permanent deletion.");
}

// Kick off
(async () => {
  try {
    await orchestrate();
    log("âœ… Orchestrator finished.");
    log("Next steps:");
    log("  - Review the extracted i18n strings at i18n/extracted_strings.json");
    log("  - Inspect isolated files under .isolated_trash/* and src/.shared_quarantine/*");
    log("  - Run `npx playwright test tests/auto_generated/` to run generated tests (or view report above).");
  } catch (err) {
    console.error("Fatal orchestrator error:", err);
  }
})();
