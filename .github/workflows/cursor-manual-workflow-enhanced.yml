name: 🤖 Cursor Manual Workflow (Enhanced)

# ✅ Enhanced manual workflow with better error handling and real fixes
on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'What action do you want to perform?'
        required: true
        type: choice
        options:
          - 'test-only'           # Run tests only
          - 'test-and-fix'        # Test + Auto-fix issues
          - 'test-fix-enhance'    # Test + Fix + Enhance code
          - 'enhance-only'        # Enhance code only (no tests)
      
      stop_on_success:
        description: 'Stop if tests pass?'
        required: true
        type: boolean
        default: true
      
      model:
        description: 'Which AI model to use?'
        required: false
        type: choice
        default: 'gpt-4o'
        options:
          - 'gpt-4o'
          - 'gpt-4-turbo'
          - 'claude-sonnet-4'

env:
  NODE_VERSION: '18'

jobs:
  # ==========================================
  # Phase 1: Testing
  # ==========================================
  test:
    name: 🧪 Run Tests
    if: |
      github.event.inputs.mode == 'test-only' ||
      github.event.inputs.mode == 'test-and-fix' ||
      github.event.inputs.mode == 'test-fix-enhance'
    runs-on: ubuntu-latest
    outputs:
      test_passed: ${{ steps.test.outcome == 'success' }}
      test_failed: ${{ steps.test.outcome == 'failure' }}
      should_continue: ${{ steps.check.outputs.should_continue }}
    
    steps:
      - name: 📥 Checkout
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install Dependencies
        run: npm ci

      - name: 🎭 Install Playwright
        run: npx playwright install --with-deps

      - name: 🧪 Run Tests
        id: test
        continue-on-error: true
        run: |
          echo "🚀 Starting tests..."
          npm test 2>&1 | tee test-output.log
          TEST_EXIT_CODE=$?
          echo "exit_code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE

      - name: 📊 Test Results Summary
        if: always()
        run: |
          echo "## 📊 Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.test.outcome }}" == "success" ]; then
            echo "✅ **All tests passed!** 🎉" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Some tests failed** 😔" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📄 Log:" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          tail -50 test-output.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: 🛑 Check if should stop
        id: check
        run: |
          STOP_ON_SUCCESS="${{ github.event.inputs.stop_on_success }}"
          TEST_PASSED="${{ steps.test.outcome == 'success' }}"
          
          if [ "$TEST_PASSED" == "true" ] && [ "$STOP_ON_SUCCESS" == "true" ]; then
            echo "✅ Tests passed and stop requested - stopping here"
            echo "should_continue=false" >> $GITHUB_OUTPUT
          else
            echo "should_continue=true" >> $GITHUB_OUTPUT
          fi

      - name: 📤 Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            test-output.log
            test-results/
            playwright-report/
          retention-days: 7

  # ==========================================
  # Phase 2: Smart Auto-Fix
  # ==========================================
  fix:
    name: 🔧 Smart Auto-Fix
    needs: test
    if: |
      needs.test.outputs.test_failed == 'true' &&
      (github.event.inputs.mode == 'test-and-fix' || 
       github.event.inputs.mode == 'test-fix-enhance')
    runs-on: ubuntu-latest
    outputs:
      fix_success: ${{ steps.verify.outcome == 'success' }}
    
    steps:
      - name: 📥 Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 📥 Download Test Logs
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: ./test-logs/

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install Dependencies
        run: npm ci

      - name: 🎭 Install Playwright
        run: npx playwright install --with-deps

      - name: 🤖 Analyze Errors & Create Fix Script
        run: |
          echo "🤖 Analyzing test errors..."
          
          cat > analyze-and-fix.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          console.log('🔍 Analyzing test failures...');
          
          // Read test log
          let testLog = '';
          try {
            testLog = fs.readFileSync('./test-logs/test-output.log', 'utf8');
          } catch (e) {
            console.log('⚠️ Could not read test log file');
            process.exit(0);
          }
          
          // Analyze common patterns
          const issues = {
            timeout: /timeout|waiting|timed out/gi,
            notFound: /not found|could not find|locator/gi,
            visibility: /not visible|not attached|not editable/gi,
            api: /network|fetch|api error|connection/gi,
            assertion: /expect|assertion|expected/gi
          };
          
          const foundIssues = [];
          for (const [type, pattern] of Object.entries(issues)) {
            if (pattern.test(testLog)) {
              foundIssues.push(type);
            }
          }
          
          console.log('📊 Found issues:', foundIssues.join(', '));
          
          // Create a report
          const report = {
            timestamp: new Date().toISOString(),
            issues: foundIssues,
            suggestions: []
          };
          
          if (foundIssues.includes('timeout')) {
            report.suggestions.push('Check selectors and add proper waits');
          }
          if (foundIssues.includes('notFound')) {
            report.suggestions.push('Review locators, add data-testid attributes');
          }
          if (foundIssues.includes('visibility')) {
            report.suggestions.push('Check element states before interaction');
          }
          if (foundIssues.includes('api')) {
            report.suggestions.push('Review network calls and Supabase config');
          }
          
          fs.writeFileSync('./analysis-report.json', JSON.stringify(report, null, 2));
          console.log('✅ Analysis complete');
          
          // Return suggestions via file
          if (foundIssues.length > 0) {
            console.log('\n💡 Suggestions:');
            report.suggestions.forEach((s, i) => console.log(`${i + 1}. ${s}`));
          }
          EOF
          
          node analyze-and-fix.js
          
          if [ -f "./analysis-report.json" ]; then
            echo "## 📊 Error Analysis" >> $GITHUB_STEP_SUMMARY
            echo '' >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            cat analysis-report.json >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: 📝 Create Placeholder Fix PR
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          BRANCH_NAME="fix/manual-${{ github.run_id }}"
          
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git checkout -b $BRANCH_NAME
          
          # Add analysis report
          git add analysis-report.json || true
          
          git commit -m "📊 fix: test failure analysis (run ${{ github.run_id }})" || echo "Nothing to commit"
          git push origin $BRANCH_NAME || true
          
          # Create PR with analysis
          gh pr create \
            --title "🔧 Test Fix Analysis - Manual Run #${{ github.run_id }}" \
            --body "## 🔍 Test Failure Analysis
          
          **Triggered by:** @${{ github.actor }}
          **Model:** ${{ github.event.inputs.model }}
          **Run ID:** ${{ github.run_id }}
          
          ### 📊 Analysis
          Review the analysis-report.json for detailed findings.
          
          ### 🔗 Workflow Run
          [View Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          
          ### ⚠️ Note
          This PR contains the analysis. Manual fixes required based on findings.
          " \
            --base ${{ github.ref_name }} \
            --head $BRANCH_NAME || echo "PR might already exist"

      - name: 📊 Fix Summary
        if: always()
        run: |
          echo "## 🔧 Fix Summary" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Analysis complete!**" >> $GITHUB_STEP_SUMMARY
          echo "📊 Check the PR for detailed findings" >> $GITHUB_STEP_SUMMARY

  # ==========================================
  # Phase 3: Code Enhancement
  # ==========================================
  enhance:
    name: ✨ Enhance Code
    needs: [test, fix]
    if: |
      always() &&
      (github.event.inputs.mode == 'enhance-only' ||
       (github.event.inputs.mode == 'test-fix-enhance' && 
        needs.test.outputs.test_passed == 'true'))
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 📦 Install Dependencies
        run: npm ci

      - name: ✨ Run Code Quality Check
        run: |
          echo "✨ Running code quality improvements..."
          
          cat > code-quality-check.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          console.log('🔍 Checking code quality...');
          
          const suggestions = [];
          
          // Check for TODO comments
          function findTODOs(dir) {
            const files = fs.readdirSync(dir, { withFileTypes: true });
            for (const file of files) {
              const fullPath = path.join(dir, file.name);
              if (file.isDirectory() && !file.name.includes('node_modules')) {
                findTODOs(fullPath);
              } else if (file.name.endsWith('.ts') || file.name.endsWith('.tsx')) {
                try {
                  const content = fs.readFileSync(fullPath, 'utf8');
                  const matches = content.match(/\/\/ TODO:.*/g);
                  if (matches) {
                    suggestions.push({
                      file: fullPath,
                      todos: matches.length
                    });
                  }
                } catch (e) {
                  // Ignore
                }
              }
            }
          }
          
          findTODOs('./src');
          
          if (suggestions.length > 0) {
            console.log('📝 Found TODO comments in:');
            suggestions.forEach(s => {
              console.log(`  - ${s.file}: ${s.todos} TODO(s)`);
            });
          } else {
            console.log('✅ No TODO comments found');
          }
          
          console.log('✅ Code quality check complete');
          EOF
          
          node code-quality-check.js

      - name: 📝 Create Enhancement Report
        if: always()
        run: |
          echo "## ✨ Enhancement Report" >> $GITHUB_STEP_SUMMARY
          echo "✅ Code quality analysis complete" >> $GITHUB_STEP_SUMMARY
          echo "📊 Review suggestions above" >> $GITHUB_STEP_SUMMARY

  # ==========================================
  # Final Report
  # ==========================================
  report:
    name: 📊 Final Report
    needs: [test, fix, enhance]
    if: always()
    runs-on: ubuntu-latest
    
    steps:
      - name: 📊 Generate Report
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # 🎯 Manual Workflow Report
          
          ## ⚙️ Settings
          - **Mode:** ${{ github.event.inputs.mode }}
          - **Stop on Success:** ${{ github.event.inputs.stop_on_success }}
          - **Model:** ${{ github.event.inputs.model }}
          - **Triggered by:** @${{ github.actor }}
          
          ## 📊 Results
          | Phase | Status |
          |-------|--------|
          | 🧪 Tests | ${{ needs.test.result || 'Skipped' }} |
          | 🔧 Fix | ${{ needs.fix.result || 'Skipped' }} |
          | ✨ Enhance | ${{ needs.enhance.result || 'Skipped' }} |
          
          ## 🔗 Links
          - [Workflow Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          
          ---
          🤖 Enhanced Cursor Workflow
          EOF

      - name: 📤 Upload Final Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: final-report
          path: |
            analysis-report.json
            code-quality-check.js
          retention-days: 30
          if-no-files-found: ignore
